# Advanced Multi-Dimensional Labeler Documentation

## Overview

The NECROZMAv2 advanced labeler provides **Numba JIT-optimized** multi-dimensional outcome labeling with support for:
- **Multi-target**: Multiple take-profit levels
- **Multi-stop**: Multiple stop-loss levels  
- **Multi-horizon**: Multiple time horizons
- **Advanced metrics**: MFE, MAE, R-Multiple
- **Intelligent caching**: Avoid recalculation

## Performance

- **50-100x faster** than pure Python implementation
- **180 label configurations** in ~1.37 seconds (0.01s per config)
- **25x speedup** with caching enabled

## Configuration

### config.yaml

```yaml
labeling:
  target_pips: [5, 10, 15, 20, 30, 50]   # Take profit levels in pips
  stop_pips: [5, 10, 15, 20, 30]          # Stop loss levels in pips
  horizons: [30, 60, 120, 240, 480, 1440] # Time horizons in minutes
  use_numba: true                          # Enable Numba JIT compilation
  use_cache: true                          # Cache labels to disk
  cache_dir: "data/labels"                 # Label cache directory
```

### Label Config Naming Convention

Labels are named using the format: `T{target}_S{stop}_H{horizon}`

Examples:
- `T5_S5_H30` â†’ TP=5 pips, SL=5 pips, Horizon=30 min
- `T10_S5_H60` â†’ TP=10 pips, SL=5 pips, Horizon=60 min
- `T50_S30_H1440` â†’ TP=50 pips, SL=30 pips, Horizon=1 day

## Usage

### Multi-Config Mode (Recommended)

```python
from core.label import run_label_workflow
import yaml

# Load config
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Create labels for all configurations
labels_dict = run_label_workflow(universe_df, config)

# labels_dict is a dictionary:
# {
#   'T5_S5_H30': DataFrame with labels,
#   'T10_S5_H60': DataFrame with labels,
#   ...
# }

# Iterate over label configs
for label_config, labels in labels_dict.items():
    print(f"Processing {label_config}...")
    # Use labels for backtesting
```

### Simple Mode (Backward Compatible)

```python
from core.label import run_label_workflow

# Simple mode with fixed TP/SL
labels_dict = run_label_workflow(
    universe_df, 
    config=None,
    tp_pips=10.0, 
    sl_pips=5.0
)

# Returns {'default': DataFrame with labels}
labels = labels_dict['default']
```

## Label DataFrame Columns

Each label configuration returns a DataFrame with these columns:

### Outcome Columns
- `up_outcome`: Long trade outcome ('target', 'stop', or 'timeout')
- `down_outcome`: Short trade outcome ('target', 'stop', or 'timeout')

### Binary Labels (for compatibility)
- `label_long`: 1 if long target hit, 0 if stop hit, -1 if timeout
- `label_short`: 1 if short target hit, 0 if stop hit, -1 if timeout

### Advanced Metrics
- `up_mfe`: Maximum Favorable Excursion for long trades (pips)
- `up_mae`: Maximum Adverse Excursion for long trades (pips)
- `down_mfe`: Maximum Favorable Excursion for short trades (pips)
- `down_mae`: Maximum Adverse Excursion for short trades (pips)
- `up_r_multiple`: R-Multiple for long trades (actual P/L / risk)
- `down_r_multiple`: R-Multiple for short trades (actual P/L / risk)
- `up_time_to_result`: Bars until long trade resolved
- `down_time_to_result`: Bars until short trade resolved

## Advanced Metrics Explained

### Maximum Favorable Excursion (MFE)
The maximum profit reached during the trade, measured in pips. Shows how much potential profit was available.

### Maximum Adverse Excursion (MAE)
The maximum drawdown during the trade, measured in pips. Shows how much the trade went against you.

### R-Multiple
The actual profit/loss expressed as a multiple of the initial risk:
- R = 1.0: Trade made exactly 1x the risk
- R = 2.0: Trade made 2x the risk (2:1 reward)
- R = -1.0: Trade lost exactly 1x the risk (full stop loss)
- R = 0.5: Trade made half the risk before timeout

## Integration with NECROZMAv2

The labeler integrates seamlessly with the Grande Teste workflow:

```python
# In necrozma.py
labels_dict = run_label_workflow(universe, config)

# Backtest each label config
for label_config, labels in labels_dict.items():
    for lookback in lookbacks:
        patterns = run_patterns_workflow(universe, strategies, lookback)
        ranking = run_backtest_workflow(patterns, labels, risk_levels)
        ranking['label_config'] = label_config
```

## Caching

The labeler automatically caches results to disk to avoid recalculation:

```python
# First run: Calculates labels and saves to cache
labels_dict = label_dataframe(df, use_cache=True, cache_dir='data/labels')

# Second run: Loads from cache (25x faster!)
labels_dict = label_dataframe(df, use_cache=True, cache_dir='data/labels')
```

Cache files are stored as: `data/labels/labels_{hash}.pkl`

## Example Output

```
ðŸ·ï¸  LABEL CREATION
================================================================================
âš¡ Numba JIT: ENABLED (Light Speed Mode - 50-100x faster)

Creating labels for 180 configurations...
  Targets: [5, 10, 15, 20, 30, 50]
  Stops: [5, 10, 15, 20, 30]
  Horizons: [30, 60, 120, 240, 480, 1440] minutes
  Bars per minute: 1.00

  T5_S5_H30... âœ… (0.0s) Long WR: 86.6% Short WR: 86.1%
  T5_S5_H60... âœ… (0.0s) Long WR: 86.6% Short WR: 86.1%
  ...
  T50_S30_H1440... âœ… (0.0s) Long WR: 43.8% Short WR: 23.4%

âœ… LABELS CREATED
   Total configs: 180
   Total time: 1.4s

   Label Statistics:
   - Best avg win rate: T5_S30_H30 (97.0%)
================================================================================
```

## Total Scale of Grande Teste

With multi-dimensional labeling:
- **30 pairs** Ã— **25 universes** Ã— **180 label configs** Ã— **288 strategies** Ã— **22 risk levels**
- = **855,360,000 combinations** possible!

In practice, we test the best combinations based on intermediate metrics.

## Technical Details

### Numba JIT Compilation

The core labeling function `_scan_for_target_stop()` is compiled with Numba's JIT compiler:

```python
@njit(cache=True, fastmath=True)
def _scan_for_target_stop(prices_high, prices_low, candle_idx, ...):
    # Compiled to native machine code for maximum speed
    ...
```

Benefits:
- 50-100x faster than pure Python
- Compiled once, reused across runs
- Parallel processing capability

### Memory Efficiency

The labeler processes all configurations in a single pass through the data, minimizing memory usage and I/O operations.

## Troubleshooting

### Numba not installed
```bash
pip install numba>=0.56.0
```

### Cache directory doesn't exist
The labeler automatically creates the cache directory if it doesn't exist.

### Different results after code changes
Clear the cache directory to force recalculation:
```bash
rm -rf data/labels/
```

## See Also

- `core/labeler.py` - Core implementation
- `core/label.py` - Integration layer
- `config.yaml` - Configuration
- `necrozma.py` - Main workflow
